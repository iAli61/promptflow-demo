{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with prompty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Learning Objectives** - Upon completing this tutorial, you should be able to:\n",
    "\n",
    "- Write LLM application using prompty and visualize the trace of your application.\n",
    "- batch run prompty against multi lines of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install dependent packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install promptflow-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute a Prompty\n",
    "\n",
    "Prompty is a file with .prompty extension for developing prompt template. \n",
    "The prompty asset is a markdown file with a modified front matter. \n",
    "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "name: Basic Prompt\n",
      "description: A basic prompt that uses the chat API to answer questions\n",
      "model:\n",
      "    api: chat\n",
      "    configuration:\n",
      "        type: azure_openai\n",
      "        azure_deployment: gpt-4\n",
      "    parameters:\n",
      "        max_tokens: 128\n",
      "        temperature: 0.2\n",
      "inputs:\n",
      "  question:\n",
      "    type: string\n",
      "sample:\n",
      "  \"question\": \"Who is the most famous person in the world?\"\n",
      "---\n",
      "system:\n",
      "You are an AI assistant who helps people find information.\n",
      "As the assistant, you answer questions briefly, succinctly. \n",
      "\n",
      "user:\n",
      "{{question}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"basic.prompty\") as fin:\n",
    "    print(fin.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before running below cell, please configure required environment variable `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` by create an `.env` file. Please refer to `../.env.example` as an template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    # load environment variables from .env file\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"AZURE_OPENAI_API_KEY\" not in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptflow.core import Prompty\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"basic.prompty\")\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the capital of France?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can override configuration with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
    "\n",
    "# override configuration with AzureOpenAIModelConfiguration\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    # azure_endpoint=\"${env:AZURE_OPENAI_ENDPOINT}\",  # Use ${env:<ENV_NAME>} to surround the environment variable name.\n",
    "    # api_key=\"${env:AZURE_OPENAI_API_KEY}\",\n",
    "    azure_deployment=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# override configuration with OpenAIModelConfiguration\n",
    "# configuration = OpenAIModelConfiguration(\n",
    "#     base_url=\"${env:OPENAI_BASE_URL}\",\n",
    "#     api_key=\"${env:OPENAI_API_KEY}\",\n",
    "#     model=\"gpt-3.5-turbo\"\n",
    "# )\n",
    "\n",
    "override_model = {\"configuration\": configuration, \"parameters\": {\"max_tokens\": 512}}\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"basic.prompty\", model=override_model)\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the capital of France?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize trace by using start_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n"
     ]
    }
   ],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run below cell will collect a trace in trace UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun the function, which will be recorded in the trace\n",
    "question = \"What is the capital of Japan?\"\n",
    "ground_truth = \"Tokyo\"\n",
    "result = f(question=question)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval the result \n",
    "\n",
    "Note: the eval flow returns a `json_object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': '5', 'explanation': 'Tokyo is the capital of Japan.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prompty as a flow\n",
    "eval_flow = Prompty.load(\"../eval-basic/eval.prompty\")\n",
    "# execute the flow as function\n",
    "result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Batch run with multi-line data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# batch run requires promptflow-devkit package\n",
    "%pip install promptflow-devkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.client import PFClient\n",
    "\n",
    "pf = PFClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-27 14:44:14 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run basic_20250227_144414_802786, log path: /home/azureuser/.promptflow/.runs/basic_20250227_144414_802786/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=basic_20250227_144414_802786\n",
      "2025-02-27 14:44:20 +0000   56126 execution.bulk     INFO     Process 56163 terminated.\n",
      "2025-02-27 14:44:20 +0000   56126 execution.bulk     WARNING  Process 56167 had been terminated.\n",
      "2025-02-27 14:44:20 +0000   56126 execution.bulk     WARNING  Process 56158 had been terminated.\n",
      "2025-02-27 14:44:14 +0000   55947 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-27 14:44:15 +0000   55947 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
      "2025-02-27 14:44:17 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(56163)-Line number(0) start execution.\n",
      "2025-02-27 14:44:17 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(56158)-Line number(1) start execution.\n",
      "2025-02-27 14:44:17 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(56167)-Line number(2) start execution.\n",
      "2025-02-27 14:44:17 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(56163)-Line number(0) completed.\n",
      "2025-02-27 14:44:18 +0000   55947 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-02-27 14:44:18 +0000   55947 execution.bulk     INFO     Average execution time for completed lines: 3.0 seconds. Estimated time for incomplete lines: 6.0 seconds.\n",
      "2025-02-27 14:44:19 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(56158)-Line number(1) completed.\n",
      "2025-02-27 14:44:19 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(56167)-Line number(2) completed.\n",
      "2025-02-27 14:44:20 +0000   55947 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-02-27 14:44:20 +0000   55947 execution.bulk     INFO     Average execution time for completed lines: 1.67 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-27 14:44:20 +0000   55947 execution.bulk     INFO     The thread monitoring the process [56163-ForkProcess-2:2] will be terminated.\n",
      "2025-02-27 14:44:20 +0000   55947 execution.bulk     INFO     The thread monitoring the process [56167-ForkProcess-2:3] will be terminated.\n",
      "2025-02-27 14:44:20 +0000   55947 execution.bulk     INFO     The thread monitoring the process [56158-ForkProcess-2:1] will be terminated.\n",
      "2025-02-27 14:44:20 +0000   56163 execution.bulk     INFO     The process [56163] has received a terminate signal.\n",
      "2025-02-27 14:44:20 +0000   56158 execution.bulk     INFO     The process [56158] has received a terminate signal.\n",
      "2025-02-27 14:44:20 +0000   56167 execution.bulk     INFO     The process [56167] has received a terminate signal.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"basic_20250227_144414_802786\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-27 14:44:14.802662+00:00\"\n",
      "Duration: \"0:00:06.466195\"\n",
      "Output path: \"/home/azureuser/.promptflow/.runs/basic_20250227_144414_802786\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flow = \"./basic.prompty\"  # path to the prompty file\n",
    "data = \"./data.jsonl\"  # path to the data file\n",
    "\n",
    "# create run with the flow and data\n",
    "base_run = pf.run(\n",
    "    flow=flow,\n",
    "    data=data,\n",
    "    column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "    },\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is capital of France?</td>\n",
       "      <td>0</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the meaning of life?</td>\n",
       "      <td>1</td>\n",
       "      <td>The meaning of life is a philosophical questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the planets in Sun system?</td>\n",
       "      <td>2</td>\n",
       "      <td>The planets in the Solar System are:\\n\\n1. Mer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       inputs.question  inputs.line_number  \\\n",
       "0           What is capital of France?                   0   \n",
       "1         What is the meaning of life?                   1   \n",
       "2  What are the planets in Sun system?                   2   \n",
       "\n",
       "                                      outputs.output  \n",
       "0                    The capital of France is Paris.  \n",
       "1  The meaning of life is a philosophical questio...  \n",
       "2  The planets in the Solar System are:\\n\\n1. Mer...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = pf.get_details(base_run)\n",
    "details.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate your flow\n",
    "Then you can use an evaluation method to evaluate your flow. The evaluation methods are also flows which usually using LLM assert the produced output matches certain expectation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation on the previous batch run\n",
    "The **base_run** is the batch run we completed in step 2 above, for web-classification flow with \"data.jsonl\" as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-27 14:44:21 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run eval_basic_20250227_144421_332312, log path: /home/azureuser/.promptflow/.runs/eval_basic_20250227_144421_332312/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=eval_basic_20250227_144421_332312\n",
      "2025-02-27 14:44:24 +0000   56342 execution.bulk     INFO     Process 56390 terminated.\n",
      "2025-02-27 14:44:24 +0000   56342 execution.bulk     WARNING  Process 56382 had been terminated.\n",
      "2025-02-27 14:44:24 +0000   56342 execution.bulk     WARNING  Process 56397 had been terminated.\n",
      "2025-02-27 14:44:21 +0000   55947 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-27 14:44:21 +0000   55947 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
      "2025-02-27 14:44:23 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-4:2)-Process id(56390)-Line number(0) start execution.\n",
      "2025-02-27 14:44:23 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-4:3)-Process id(56397)-Line number(1) start execution.\n",
      "2025-02-27 14:44:23 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-4:1)-Process id(56382)-Line number(2) start execution.\n",
      "2025-02-27 14:44:23 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-4:2)-Process id(56390)-Line number(0) completed.\n",
      "2025-02-27 14:44:23 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-4:1)-Process id(56382)-Line number(2) completed.\n",
      "2025-02-27 14:44:24 +0000   55947 execution.bulk     INFO     Process name(ForkProcess-4:3)-Process id(56397)-Line number(1) completed.\n",
      "2025-02-27 14:44:24 +0000   55947 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-02-27 14:44:24 +0000   55947 execution.bulk     INFO     Average execution time for completed lines: 1.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-27 14:44:24 +0000   55947 execution.bulk     INFO     The thread monitoring the process [56390-ForkProcess-4:2] will be terminated.\n",
      "2025-02-27 14:44:24 +0000   55947 execution.bulk     INFO     The thread monitoring the process [56382-ForkProcess-4:1] will be terminated.\n",
      "2025-02-27 14:44:24 +0000   55947 execution.bulk     INFO     The thread monitoring the process [56397-ForkProcess-4:3] will be terminated.\n",
      "2025-02-27 14:44:24 +0000   56390 execution.bulk     INFO     The process [56390] has received a terminate signal.\n",
      "2025-02-27 14:44:24 +0000   56382 execution.bulk     INFO     The process [56382] has received a terminate signal.\n",
      "2025-02-27 14:44:24 +0000   56397 execution.bulk     INFO     The process [56397] has received a terminate signal.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"eval_basic_20250227_144421_332312\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-27 14:44:21.332170+00:00\"\n",
      "Duration: \"0:00:04.108670\"\n",
      "Output path: \"/home/azureuser/.promptflow/.runs/eval_basic_20250227_144421_332312\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_prompty = \"../eval-basic/eval.prompty\"\n",
    "\n",
    "eval_run = pf.run(\n",
    "    flow=eval_prompty,\n",
    "    data=\"./data.jsonl\",  # path to the data file\n",
    "    run=base_run,  # specify base_run as the run you want to evaluate\n",
    "    column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "        \"answer\": \"${run.outputs.output}\",  # TODO refine this mapping\n",
    "        \"ground_truth\": \"${data.ground_truth}\",\n",
    "    },\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.score</th>\n",
       "      <th>outputs.explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is capital of France?</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly identifies Paris as the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the meaning of life?</td>\n",
       "      <td>The meaning of life is a philosophical questio...</td>\n",
       "      <td>The meaning of life is subjective and can vary...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer provides a comprehensive explanatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the planets in Sun system?</td>\n",
       "      <td>The planets in the Solar System are:\\n\\n1. Mer...</td>\n",
       "      <td>The planets in the Solar System are Mercury, V...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly lists all the planets in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       inputs.question  \\\n",
       "0           What is capital of France?   \n",
       "1         What is the meaning of life?   \n",
       "2  What are the planets in Sun system?   \n",
       "\n",
       "                                       inputs.answer  \\\n",
       "0                    The capital of France is Paris.   \n",
       "1  The meaning of life is a philosophical questio...   \n",
       "2  The planets in the Solar System are:\\n\\n1. Mer...   \n",
       "\n",
       "                                 inputs.ground_truth  inputs.line_number  \\\n",
       "0                                              Paris                   0   \n",
       "1  The meaning of life is subjective and can vary...                   1   \n",
       "2  The planets in the Solar System are Mercury, V...                   2   \n",
       "\n",
       "   outputs.score                                outputs.explanation  \n",
       "0              5  The answer correctly identifies Paris as the c...  \n",
       "1              5  The answer provides a comprehensive explanatio...  \n",
       "2              5  The answer correctly lists all the planets in ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = pf.get_details(eval_run)\n",
    "details.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "The HTML file is generated at '/tmp/pf-visualize-detail-gr2anlqn.html'.\n",
      "Trying to view the result in a web browser...\n",
      "Successfully visualized from the web browser.\n"
     ]
    }
   ],
   "source": [
    "# visualize run using ui\n",
    "pf.visualize([base_run, eval_run])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "By now you've successfully run your first prompt flow and even did evaluation on it. That's great!\n",
    "\n",
    "You can check out more examples:\n",
    "- [Basic Chat](https://github.com/microsoft/promptflow/tree/main/examples/prompty/chat-basic): demonstrates how to create a chatbot that can remember previous interactions and use the conversation history to generate next message."
   ]
  }
 ],
 "metadata": {
  "build_doc": {
   "author": [
    "lalala123123@github.com",
    "wangchao1230@github.com"
   ],
   "category": "local",
   "section": "Prompty",
   "weight": 10
  },
  "description": "A quickstart tutorial to run a prompty and evaluate it.",
  "kernelspec": {
   "display_name": "pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "resources": "examples/requirements.txt, examples/prompty/basic, examples/prompty/eval-basic"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
