{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with PDF - test, evaluation and experimentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will walk you through how to use prompt flow Python SDK to test, evaluate and experiment with the \"Chat with PDF\" flow.\n",
    "\n",
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create connections\n",
    "Connection in prompt flow is for managing settings of your application behaviors incl. how to talk to different services (Azure OpenAI for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
      "WARNING:opentelemetry.metrics._internal:Overriding of current MeterProvider is not allowed\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweden-aoai (AzureOpenAI)\n",
      "doc-intelligence-connection (Custom)\n",
      "acs-connection (CognitiveSearch)\n",
      "aoaisweden505 (AzureOpenAI)\n",
      "open_ai_connection (AzureOpenAI)\n"
     ]
    }
   ],
   "source": [
    "import promptflow\n",
    "\n",
    "pf = promptflow.PFClient()\n",
    "\n",
    "# List all the available connections\n",
    "for c in pf.connections.list():\n",
    "    print(c.name + \" (\" + c.type + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to have a connection named \"open_ai_connection\" to run the chat_with_pdf flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing connection\n",
      "auth_mode: key\n",
      "name: open_ai_connection\n",
      "module: promptflow.connections\n",
      "type: azure_open_ai\n",
      "api_key: '******'\n",
      "api_base: https://aoai-sweden-505.openai.azure.com/\n",
      "api_type: azure\n",
      "api_version: '2024-02-01'\n",
      "resource_id: \n",
      "  /subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourceGroups/re-aoai-505/providers/Microsoft.CognitiveServices/accounts/aoai-sweden-505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create needed connection\n",
    "from promptflow.entities import AzureOpenAIConnection, OpenAIConnection\n",
    "\n",
    "try:\n",
    "    conn_name = \"open_ai_connection\"\n",
    "    conn = pf.connections.get(name=conn_name)\n",
    "    print(\"using existing connection\")\n",
    "except:\n",
    "    # Follow https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal to create an Azure OpenAI resource.\n",
    "    connection = AzureOpenAIConnection(\n",
    "        name=conn_name,\n",
    "        api_key=\"<user-input>\",\n",
    "        api_base=\"<test_base>\",\n",
    "        api_type=\"azure\",\n",
    "        api_version=\"<test_version>\",\n",
    "    )\n",
    "\n",
    "    # use this if you have an existing OpenAI account\n",
    "    # connection = OpenAIConnection(\n",
    "    #     name=conn_name,\n",
    "    #     api_key=\"<user-input>\",\n",
    "    # )\n",
    "    conn = pf.connections.create_or_update(connection)\n",
    "    print(\"successfully created connection\")\n",
    "\n",
    "print(conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the flow\n",
    "\n",
    "**Note**: this sample uses `predownloaded PDFs` and `prebuilt FAISS Index` to speed up execution time.\n",
    "You can remove the folders to start a fresh run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Start to run 6 nodes with concurrency level 16.\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Executing node setup_env. node run id: bc945476-ea24-4898-ab0f-28ca6922ff98_setup_env_0\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Node setup_env completes.\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Executing node download_tool. node run id: bc945476-ea24-4898-ab0f-28ca6922ff98_download_tool_0\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Executing node rewrite_question_tool. node run id: bc945476-ea24-4898-ab0f-28ca6922ff98_rewrite_question_tool_0\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     [download_tool in line 0 (index starts from 0)] stdout> Pdf already exists in /home/azureuser/promptflow-demo/chat-with-pdf/flow/chat_with_pdf/.pdfs/https___arxiv.org_pdf_1810.04805.pdf.pdf\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Node download_tool completes.\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Executing node build_index_tool. node run id: bc945476-ea24-4898-ab0f-28ca6922ff98_build_index_tool_0\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Chunk size: 1024, chunk overlap: 64\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index path: /home/azureuser/promptflow-demo/chat-with-pdf/flow/chat_with_pdf/.index/.pdfs/https___arxiv.org_pdf_1810.04805.pdf.pdf.index_1024_64\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index already exists, bypassing index creation\n",
      "2025-02-27 08:51:39 +0000   73187 execution.flow     INFO     Node build_index_tool completes.\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x18df30a9dee2cd387a17e1471f9182f5\n",
      "2025-02-27 08:51:41 +0000   73187 execution.flow     INFO     [rewrite_question_tool in line 0 (index starts from 0)] stdout> Rewritten question: What does BERT stand for in the context of natural language processing?\n",
      "2025-02-27 08:51:41 +0000   73187 execution.flow     INFO     Node rewrite_question_tool completes.\n",
      "2025-02-27 08:51:41 +0000   73187 execution.flow     INFO     Executing node find_context_tool. node run id: bc945476-ea24-4898-ab0f-28ca6922ff98_find_context_tool_0\n",
      "2025-02-27 08:51:41 +0000   73187 execution.flow     INFO     Node find_context_tool completes.\n",
      "2025-02-27 08:51:41 +0000   73187 execution.flow     INFO     Executing node qna_tool. node run id: bc945476-ea24-4898-ab0f-28ca6922ff98_qna_tool_0\n",
      "2025-02-27 08:51:43 +0000   73187 execution.flow     INFO     Node qna_tool completes.\n",
      "{'answer': 'BERT stands for Bidirectional Encoder Representations from Transformers in the context of natural language processing.', 'context': ['BERT: Pre-training of Deep Bidirectional Transformers for\\nLanguage Understanding\\nJacob Devlin Ming-Wei Chang Kenton Lee Kristina Toutanova\\nGoogle AI Language\\nfjacobdevlin,mingweichang,kentonl,kristout g@google.com\\nAbstract\\nWe introduce a new language representa-\\ntion model called BERT , which stands for\\nBidirectional Encoder Representations from\\nTransformers. Unlike recent language repre-\\nsentation models (Peters et al., 2018a; Rad-\\nford et al., 2018), BERT is designed to pre-\\ntrain deep bidirectional representations from\\nunlabeled text by jointly conditioning on both\\nleft and right context in all layers. As a re-\\nsult, the pre-trained BERT model can be ﬁne-\\ntuned with just one additional output layer\\nto create state-of-the-art models for a wide\\nrange of tasks, such as question answering and\\nlanguage inference, without substantial task-\\nspeciﬁc architecture modiﬁcations.\\nBERT is conceptually simple and empirically\\npowerful. It obtains new state-of-the-art re-\\nsults on eleven natural language processing\\ntasks,', 'e 1 will serve\\nas a running example for this section.\\nA distinctive feature of BERT is its uniﬁed ar-\\nchitecture across different tasks. There is mini-mal difference between the pre-trained architec-\\nture and the ﬁnal downstream architecture.\\nModel Architecture BERT’s model architec-\\nture is a multi-layer bidirectional Transformer en-\\ncoder based on the original implementation de-\\nscribed in Vaswani et al. (2017) and released in\\nthetensor2tensor library.1Because the use\\nof Transformers has become common and our im-\\nplementation is almost identical to the original,\\nwe will omit an exhaustive background descrip-\\ntion of the model architecture and refer readers to\\nVaswani et al. (2017) as well as excellent guides\\nsuch as “The Annotated Transformer.”2\\nIn this work, we denote the number of layers\\n(i.e., Transformer blocks) as L, the hidden size as\\nH, and the number of self-attention heads as A.3\\nWe primarily report results on two model sizes:\\nBERT BASE (L=12, H=768, A=12, Total Param-\\neters=110M) and BERT LARGE (L', 'g BERT\\nFine-tuning is straightforward since the self-\\nattention mechanism in the Transformer al-\\nlows BERT to model many downstream tasks—\\nwhether they involve single text or text pairs—by\\nswapping out the appropriate inputs and outputs.\\nFor applications involving text pairs, a common\\npattern is to independently encode text pairs be-\\nfore applying bidirectional cross attention, such\\nas Parikh et al. (2016); Seo et al. (2017). BERT\\ninstead uses the self-attention mechanism to unify\\nthese two stages, as encoding a concatenated text\\npair with self-attention effectively includes bidi-\\nrectional cross attention between two sentences.\\nFor each task, we simply plug in the task-\\nspeciﬁc inputs and outputs into BERT and ﬁne-\\ntune all the parameters end-to-end. At the in-\\nput, sentence Aand sentence Bfrom pre-training\\nare analogous to (1) sentence pairs in paraphras-\\ning, (2) hypothesis-premise pairs in entailment, (3)\\nquestion-passage pairs in question answering, and(4) a degenerate text- ?pair in text classiﬁcation\\no', 'm one or more layers without ﬁne-tuning\\nany parameters of BERT. These contextual em-\\nbeddings are used as input to a randomly initial-\\nized two-layer 768-dimensional BiLSTM before\\nthe classiﬁcation layer.\\nResults are presented in Table 7. BERT LARGE\\nperforms competitively with state-of-the-art meth-\\nods. The best performing method concatenates the\\ntoken representations from the top four hidden lay-\\ners of the pre-trained Transformer, which is only\\n0.3 F1 behind ﬁne-tuning the entire model. This\\ndemonstrates that BERT is effective for both ﬁne-\\ntuning and feature-based approaches.\\n6 Conclusion\\nRecent empirical improvements due to transfer\\nlearning with language models have demonstrated\\nthat rich, unsupervised pre-training is an integral\\npart of many language understanding systems. In\\nparticular, these results enable even low-resource\\ntasks to beneﬁt from deep unidirectional architec-\\ntures. Our major contribution is further general-\\nizing these ﬁndings to deep bidirectional architec-\\ntures, allowing the same p', '.\\n• We show that pre-trained representations reduce\\nthe need for many heavily-engineered task-\\nspeciﬁc architectures. BERT is the ﬁrst ﬁne-\\ntuning based representation model that achieves\\nstate-of-the-art performance on a large suite\\nof sentence-level andtoken-level tasks, outper-\\nforming many task-speciﬁc architectures.\\n• BERT advances the state of the art for eleven\\nNLP tasks. The code and pre-trained mod-\\nels are available at https://github.com/\\ngoogle-research/bert .\\n2 Related Work\\nThere is a long history of pre-training general lan-\\nguage representations, and we brieﬂy review the\\nmost widely-used approaches in this section.\\n2.1 Unsupervised Feature-based Approaches\\nLearning widely applicable representations of\\nwords has been an active area of research for\\ndecades, including non-neural (Brown et al., 1992;\\nAndo and Zhang, 2005; Blitzer et al., 2006) and\\nneural (Mikolov et al., 2013; Pennington et al.,\\n2014) methods. Pre-trained word embeddings\\nare an integral part of modern NLP systems, of-\\nfering signiﬁc']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x4ca7d7fb900f1409a3d18e5865c3bed8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xf7f851022d2c2c01931801d1be815b30\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xda3ccf5fe4e4a9bcf888c157f6014132\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xac5578e82905660f28e29e8d984acc5b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xae237c6f528918c592d8da8cb26a9513\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xc98521354913eb3e45e9471e7bb8d47d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xeccaa08768b9144b081af500eafed6f4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xdf29a8114a9c0ffd3b58205ce60584fe\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x7bfef3dc0281828eb9174e1505187879\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x8307a78e86ebeb6de9fd2b786d0ccb6d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x90cf7624dd3c1d817b487f6471756135\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xd89778ac30aa2ec70b49ded9b98e9b2f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x147557a0ef4597d6f0f7e759c52ba49d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xa2ce7bfe3f55f90d41d1477dba0420b6\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0xe1ada24eb4f782528f83952b9431ff27\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow&uiTraceId=0x4538cb6a359d1c8badec3267b46ecafb\n"
     ]
    }
   ],
   "source": [
    "# ./chat_with_pdf/.pdfs/ stores predownloaded PDFs\n",
    "# ./chat_with_pdf/.index/ stores prebuilt index files\n",
    "\n",
    "output = pf.flows.test(\n",
    "    \".\",\n",
    "    inputs={\n",
    "        \"chat_history\": [],\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/1810.04805.pdf\",\n",
    "        \"question\": \"what is BERT?\",\n",
    "    },\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the flow with a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-27 08:51:50 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run flow_variant_0_20250227_085150_740749, log path: /home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085150_740749/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=flow_variant_0_20250227_085150_740749\n",
      "2025-02-27 08:52:11 +0000   76430 execution.bulk     INFO     Process 76506 terminated.\n",
      "2025-02-27 08:52:11 +0000   76430 execution.bulk     WARNING  Process 76513 had been terminated.\n",
      "2025-02-27 08:52:11 +0000   76430 execution.bulk     WARNING  Process 76498 had been terminated.\n",
      "2025-02-27 08:51:51 +0000   73187 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-27 08:51:53 +0000   73187 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
      "2025-02-27 08:51:55 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(76498)-Line number(0) start execution.\n",
      "2025-02-27 08:51:55 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(76506)-Line number(1) start execution.\n",
      "2025-02-27 08:51:55 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(76513)-Line number(2) start execution.\n",
      "2025-02-27 08:51:58 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(76506)-Line number(1) completed.\n",
      "2025-02-27 08:51:59 +0000   73187 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-02-27 08:51:59 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 6.0 seconds. Estimated time for incomplete lines: 12.0 seconds.\n",
      "2025-02-27 08:52:10 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(76498)-Line number(0) completed.\n",
      "2025-02-27 08:52:11 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(76513)-Line number(2) completed.\n",
      "2025-02-27 08:52:11 +0000   73187 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-02-27 08:52:11 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 6.01 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-27 08:52:11 +0000   73187 execution.bulk     INFO     The thread monitoring the process [76506-ForkProcess-2:2] will be terminated.\n",
      "2025-02-27 08:52:11 +0000   73187 execution.bulk     INFO     The thread monitoring the process [76498-ForkProcess-2:1] will be terminated.\n",
      "2025-02-27 08:52:11 +0000   73187 execution.bulk     INFO     The thread monitoring the process [76513-ForkProcess-2:3] will be terminated.\n",
      "2025-02-27 08:52:11 +0000   76506 execution.bulk     INFO     The process [76506] has received a terminate signal.\n",
      "2025-02-27 08:52:11 +0000   76498 execution.bulk     INFO     The process [76498] has received a terminate signal.\n",
      "2025-02-27 08:52:11 +0000   76513 execution.bulk     INFO     The process [76513] has received a terminate signal.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"flow_variant_0_20250227_085150_740749\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-27 08:51:50.730803+00:00\"\n",
      "Duration: \"0:00:21.596580\"\n",
      "Output path: \"/home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085150_740749\"\n",
      "\n",
      "name: flow_variant_0_20250227_085150_740749\n",
      "created_on: '2025-02-27T08:51:50.730803+00:00'\n",
      "status: Completed\n",
      "display_name: flow_variant_0_20250227_085150_740749\n",
      "description:\n",
      "tags:\n",
      "properties:\n",
      "  flow_path: /home/azureuser/promptflow-demo/chat-with-pdf/flow\n",
      "  output_path: /home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085150_740749\n",
      "  column_mapping:\n",
      "    question: ${data.question}\n",
      "    pdf_url: ${data.pdf_url}\n",
      "    chat_history: ${data.chat_history}\n",
      "    config:\n",
      "      EMBEDDING_MODEL_DEPLOYMENT_NAME: text-embedding-ada-002\n",
      "      CHAT_MODEL_DEPLOYMENT_NAME: gpt-4\n",
      "      PROMPT_TOKEN_LIMIT: 2000\n",
      "      MAX_COMPLETION_TOKENS: 256\n",
      "      VERBOSE: true\n",
      "      CHUNK_SIZE: 1024\n",
      "      CHUNK_OVERLAP: 64\n",
      "  system_metrics:\n",
      "    total_tokens: 0\n",
      "    prompt_tokens: 0\n",
      "    completion_tokens: 0\n",
      "    duration: 20.519141\n",
      "flow_name: flow\n",
      "data: \n",
      "  /home/azureuser/promptflow-demo/chat-with-pdf/flow/data/bert-paper-qna-3-line.jsonl\n",
      "output: \n",
      "  /home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085150_740749/flow_outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./data/bert-paper-qna-3-line.jsonl\"\n",
    "\n",
    "config_2k_context = {\n",
    "    \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"text-embedding-ada-002\",\n",
    "    \"CHAT_MODEL_DEPLOYMENT_NAME\": \"gpt-4\",  # change this to the name of your deployment if you're using Azure OpenAI\n",
    "    \"PROMPT_TOKEN_LIMIT\": 2000,\n",
    "    \"MAX_COMPLETION_TOKENS\": 256,\n",
    "    \"VERBOSE\": True,\n",
    "    \"CHUNK_SIZE\": 1024,\n",
    "    \"CHUNK_OVERLAP\": 64,\n",
    "}\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"pdf_url\": \"${data.pdf_url}\",\n",
    "    \"chat_history\": \"${data.chat_history}\",\n",
    "    \"config\": config_2k_context,\n",
    "}\n",
    "run_2k_context = pf.run(flow=flow_path, data=data_path, column_mapping=column_mapping)\n",
    "pf.stream(run_2k_context)\n",
    "\n",
    "print(run_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.pdf_url</th>\n",
       "      <th>inputs.chat_history</th>\n",
       "      <th>inputs.config</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the main difference between BERT and p...</td>\n",
       "      <td>https://arxiv.org/pdf/1810.04805.pdf</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'text-embe...</td>\n",
       "      <td>0</td>\n",
       "      <td>Las diferencias clave entre BERT y los modelos...</td>\n",
       "      <td>[.\\n• We show that pre-trained representations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the size of the vocabulary used by BERT?</td>\n",
       "      <td>https://arxiv.org/pdf/1810.04805.pdf</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'text-embe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Based on the provided context, there is no inf...</td>\n",
       "      <td>[E (L=12, H=768, A=12, Total Param-\\neters=110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>论文写作中论文引言有什么注意事项？</td>\n",
       "      <td>https://grs.pku.edu.cn/docs/2018-03/2018030108...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'text-embe...</td>\n",
       "      <td>2</td>\n",
       "      <td>撰写学术论文的引言部分时，应注意以下要点：\\n\\n1. 引言内容应简明扼要，切合主题，引出论...</td>\n",
       "      <td>[须言之成理，论据可靠 ，严格遵循本学科国际通行的学术规范。 内容包括：第 一\\n章引言（或...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     inputs.question  \\\n",
       "0  What is the main difference between BERT and p...   \n",
       "1   What is the size of the vocabulary used by BERT?   \n",
       "2                                  论文写作中论文引言有什么注意事项？   \n",
       "\n",
       "                                      inputs.pdf_url inputs.chat_history  \\\n",
       "0               https://arxiv.org/pdf/1810.04805.pdf                  []   \n",
       "1               https://arxiv.org/pdf/1810.04805.pdf                  []   \n",
       "2  https://grs.pku.edu.cn/docs/2018-03/2018030108...                  []   \n",
       "\n",
       "                                       inputs.config  inputs.line_number  \\\n",
       "0  {'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'text-embe...                   0   \n",
       "1  {'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'text-embe...                   1   \n",
       "2  {'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'text-embe...                   2   \n",
       "\n",
       "                                      outputs.answer  \\\n",
       "0  Las diferencias clave entre BERT y los modelos...   \n",
       "1  Based on the provided context, there is no inf...   \n",
       "2  撰写学术论文的引言部分时，应注意以下要点：\\n\\n1. 引言内容应简明扼要，切合主题，引出论...   \n",
       "\n",
       "                                     outputs.context  \n",
       "0  [.\\n• We show that pre-trained representations...  \n",
       "1  [E (L=12, H=768, A=12, Total Param-\\neters=110...  \n",
       "2  [须言之成理，论据可靠 ，严格遵循本学科国际通行的学术规范。 内容包括：第 一\\n章引言（或...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_details(run_2k_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the \"groundedness\"\n",
    "The `eval-groundedness flow` is using ChatGPT/GPT4 model to grade the answers generated by chat-with-pdf flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-27 08:54:35 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run eval_groundedness_variant_0_20250227_085435_742659, log path: /home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085435_742659/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=eval_groundedness_variant_0_20250227_085435_742659\n",
      "2025-02-27 08:54:41 +0000   78545 execution.bulk     INFO     Process 78597 terminated.\n",
      "2025-02-27 08:54:41 +0000   78545 execution.bulk     WARNING  Process 78591 had been terminated.\n",
      "2025-02-27 08:54:41 +0000   78545 execution.bulk     WARNING  Process 78605 had been terminated.\n",
      "2025-02-27 08:54:37 +0000   73187 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-27 08:54:37 +0000   73187 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
      "2025-02-27 08:54:39 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-4:1)-Process id(78591)-Line number(0) start execution.\n",
      "2025-02-27 08:54:39 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-4:2)-Process id(78597)-Line number(1) start execution.\n",
      "2025-02-27 08:54:39 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-4:3)-Process id(78605)-Line number(2) start execution.\n",
      "2025-02-27 08:54:40 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-4:2)-Process id(78597)-Line number(1) completed.\n",
      "2025-02-27 08:54:40 +0000   73187 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-02-27 08:54:40 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 3.0 seconds. Estimated time for incomplete lines: 6.0 seconds.\n",
      "2025-02-27 08:54:40 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-4:3)-Process id(78605)-Line number(2) completed.\n",
      "2025-02-27 08:54:40 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-4:1)-Process id(78591)-Line number(0) completed.\n",
      "2025-02-27 08:54:41 +0000   73187 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-02-27 08:54:41 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 1.33 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-27 08:54:41 +0000   73187 execution.bulk     INFO     The thread monitoring the process [78597-ForkProcess-4:2] will be terminated.\n",
      "2025-02-27 08:54:41 +0000   73187 execution.bulk     INFO     The thread monitoring the process [78591-ForkProcess-4:1] will be terminated.\n",
      "2025-02-27 08:54:41 +0000   73187 execution.bulk     INFO     The thread monitoring the process [78605-ForkProcess-4:3] will be terminated.\n",
      "2025-02-27 08:54:41 +0000   78597 execution.bulk     INFO     The process [78597] has received a terminate signal.\n",
      "2025-02-27 08:54:41 +0000   78591 execution.bulk     INFO     The process [78591] has received a terminate signal.\n",
      "2025-02-27 08:54:41 +0000   78605 execution.bulk     INFO     The process [78605] has received a terminate signal.\n",
      "2025-02-27 08:54:42 +0000   73187 execution.bulk     INFO     Executing aggregation node...\n",
      "2025-02-27 08:54:42 +0000   73187 execution.bulk     INFO     Finish executing aggregation node.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"eval_groundedness_variant_0_20250227_085435_742659\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-27 08:54:35.728551+00:00\"\n",
      "Duration: \"0:00:06.449502\"\n",
      "Output path: \"/home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085435_742659\"\n",
      "\n",
      "name: eval_groundedness_variant_0_20250227_085435_742659\n",
      "created_on: '2025-02-27T08:54:35.728551+00:00'\n",
      "status: Completed\n",
      "display_name: eval_groundedness_2k_context\n",
      "description:\n",
      "tags:\n",
      "properties:\n",
      "  flow_path: /home/azureuser/promptflow-demo/evaluation/eval-groundedness\n",
      "  output_path: \n",
      "    /home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085435_742659\n",
      "  column_mapping:\n",
      "    question: ${run.inputs.question}\n",
      "    answer: ${run.outputs.answer}\n",
      "    context: ${run.outputs.context}\n",
      "  system_metrics:\n",
      "    total_tokens: 0\n",
      "    prompt_tokens: 0\n",
      "    completion_tokens: 0\n",
      "    duration: 5.0928\n",
      "flow_name: eval-groundedness\n",
      "data:\n",
      "output: \n",
      "  /home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085435_742659/flow_outputs\n",
      "run: flow_variant_0_20250227_085150_740749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_groundedness_flow_path = \"../../evaluation/eval-groundedness/\"\n",
    "eval_groundedness_2k_context = pf.run(\n",
    "    flow=eval_groundedness_flow_path,\n",
    "    run=run_2k_context,\n",
    "    column_mapping={\n",
    "        \"question\": \"${run.inputs.question}\",\n",
    "        \"answer\": \"${run.outputs.answer}\",\n",
    "        \"context\": \"${run.outputs.context}\",\n",
    "    },\n",
    "    display_name=\"eval_groundedness_2k_context\",\n",
    ")\n",
    "pf.stream(eval_groundedness_2k_context)\n",
    "\n",
    "print(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the main difference between BERT and p...</td>\n",
       "      <td>Las diferencias clave entre BERT y los modelos...</td>\n",
       "      <td>['.\\n• We show that pre-trained representation...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the size of the vocabulary used by BERT?</td>\n",
       "      <td>Based on the provided context, there is no inf...</td>\n",
       "      <td>['E (L=12, H=768, A=12, Total Param-\\neters=11...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>论文写作中论文引言有什么注意事项？</td>\n",
       "      <td>撰写学术论文的引言部分时，应注意以下要点：\\n\\n1. 引言内容应简明扼要，切合主题，引出论...</td>\n",
       "      <td>['须言之成理，论据可靠 ，严格遵循本学科国际通行的学术规范。 内容包括：第 一\\n章引言（...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     inputs.question  \\\n",
       "0  What is the main difference between BERT and p...   \n",
       "1   What is the size of the vocabulary used by BERT?   \n",
       "2                                  论文写作中论文引言有什么注意事项？   \n",
       "\n",
       "                                       inputs.answer  \\\n",
       "0  Las diferencias clave entre BERT y los modelos...   \n",
       "1  Based on the provided context, there is no inf...   \n",
       "2  撰写学术论文的引言部分时，应注意以下要点：\\n\\n1. 引言内容应简明扼要，切合主题，引出论...   \n",
       "\n",
       "                                      inputs.context  inputs.line_number  \\\n",
       "0  ['.\\n• We show that pre-trained representation...                   0   \n",
       "1  ['E (L=12, H=768, A=12, Total Param-\\neters=11...                   1   \n",
       "2  ['须言之成理，论据可靠 ，严格遵循本学科国际通行的学术规范。 内容包括：第 一\\n章引言（...                   2   \n",
       "\n",
       "   outputs.groundedness  \n",
       "0                     9  \n",
       "1                     1  \n",
       "2                     7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_details(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groundedness': 5.666666666666667}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_metrics(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'from promptflow import tool' is deprecated and will be removed in the future. Use 'from promptflow.core import tool' instead.\n",
      "WARNING:root:'from promptflow import ToolProvider' is deprecated and will be removed in the future. Use 'from promptflow.core import ToolProvider' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file is generated at '/tmp/pf-visualize-detail-u89sujog.html'.\n",
      "Trying to view the result in a web browser...\n",
      "Successfully visualized from the web browser.\n"
     ]
    }
   ],
   "source": [
    "pf.visualize(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see a web page like this. It gives you detail about how each row is graded and even the details how the evaluation run executes:\n",
    "![pf-visualize-screenshot](./media/chat-with-pdf/pf-visualize-screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try a different configuration and evaluate again - experimentation\n",
    "\n",
    "NOTE: since we only use 3 lines of test data in this example, and because of the non-deterministic nature of LLMs, don't be surprised if you see exact same metrics when you run this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-27 08:56:10 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run flow_variant_0_20250227_085610_947108, log path: /home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085610_947108/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=flow_variant_0_20250227_085610_947108\n",
      "2025-02-27 08:56:27 +0000   79837 execution.bulk     INFO     Process 79895 terminated.\n",
      "2025-02-27 08:56:27 +0000   79837 execution.bulk     WARNING  Process 79880 had been terminated.\n",
      "2025-02-27 08:56:27 +0000   79837 execution.bulk     WARNING  Process 79887 had been terminated.\n",
      "2025-02-27 08:56:12 +0000   73187 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-27 08:56:12 +0000   73187 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
      "2025-02-27 08:56:14 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-8:1)-Process id(79880)-Line number(0) start execution.\n",
      "2025-02-27 08:56:14 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-8:3)-Process id(79895)-Line number(1) start execution.\n",
      "2025-02-27 08:56:14 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-8:2)-Process id(79887)-Line number(2) start execution.\n",
      "2025-02-27 08:56:17 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-8:3)-Process id(79895)-Line number(1) completed.\n",
      "2025-02-27 08:56:17 +0000   73187 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-02-27 08:56:17 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 5.01 seconds. Estimated time for incomplete lines: 10.02 seconds.\n",
      "2025-02-27 08:56:23 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-8:2)-Process id(79887)-Line number(2) completed.\n",
      "2025-02-27 08:56:24 +0000   73187 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-02-27 08:56:24 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 6.01 seconds. Estimated time for incomplete lines: 6.01 seconds.\n",
      "2025-02-27 08:56:27 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-8:1)-Process id(79880)-Line number(0) completed.\n",
      "2025-02-27 08:56:27 +0000   73187 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-02-27 08:56:27 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 5.01 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-27 08:56:27 +0000   73187 execution.bulk     INFO     The thread monitoring the process [79895-ForkProcess-8:3] will be terminated.\n",
      "2025-02-27 08:56:27 +0000   73187 execution.bulk     INFO     The thread monitoring the process [79880-ForkProcess-8:1] will be terminated.\n",
      "2025-02-27 08:56:27 +0000   73187 execution.bulk     INFO     The thread monitoring the process [79887-ForkProcess-8:2] will be terminated.\n",
      "2025-02-27 08:56:27 +0000   79895 execution.bulk     INFO     The process [79895] has received a terminate signal.\n",
      "2025-02-27 08:56:27 +0000   79880 execution.bulk     INFO     The process [79880] has received a terminate signal.\n",
      "2025-02-27 08:56:27 +0000   79887 execution.bulk     INFO     The process [79887] has received a terminate signal.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"flow_variant_0_20250227_085610_947108\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-27 08:56:10.937704+00:00\"\n",
      "Duration: \"0:00:17.969677\"\n",
      "Output path: \"/home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085610_947108\"\n",
      "\n",
      "name: flow_variant_0_20250227_085610_947108\n",
      "created_on: '2025-02-27T08:56:10.937704+00:00'\n",
      "status: Completed\n",
      "display_name: flow_variant_0_20250227_085610_947108\n",
      "description:\n",
      "tags:\n",
      "properties:\n",
      "  flow_path: /home/azureuser/promptflow-demo/chat-with-pdf/flow\n",
      "  output_path: /home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085610_947108\n",
      "  column_mapping:\n",
      "    question: ${data.question}\n",
      "    pdf_url: ${data.pdf_url}\n",
      "    chat_history: ${data.chat_history}\n",
      "    config:\n",
      "      EMBEDDING_MODEL_DEPLOYMENT_NAME: text-embedding-ada-002\n",
      "      CHAT_MODEL_DEPLOYMENT_NAME: gpt-4\n",
      "      PROMPT_TOKEN_LIMIT: 2000\n",
      "      MAX_COMPLETION_TOKENS: 256\n",
      "      VERBOSE: true\n",
      "      CHUNK_SIZE: 1024\n",
      "      CHUNK_OVERLAP: 64\n",
      "  system_metrics:\n",
      "    total_tokens: 0\n",
      "    prompt_tokens: 0\n",
      "    completion_tokens: 0\n",
      "    duration: 16.086334\n",
      "flow_name: flow\n",
      "data: \n",
      "  /home/azureuser/promptflow-demo/chat-with-pdf/flow/data/bert-paper-qna-3-line.jsonl\n",
      "output: \n",
      "  /home/azureuser/.promptflow/.runs/flow_variant_0_20250227_085610_947108/flow_outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_3k_context = {\n",
    "    \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"text-embedding-ada-002\",\n",
    "    \"CHAT_MODEL_DEPLOYMENT_NAME\": \"gpt-4\",  # change this to the name of your deployment if you're using Azure OpenAI\n",
    "    \"PROMPT_TOKEN_LIMIT\": 3000,\n",
    "    \"MAX_COMPLETION_TOKENS\": 256,\n",
    "    \"VERBOSE\": True,\n",
    "    \"CHUNK_SIZE\": 1024,\n",
    "    \"CHUNK_OVERLAP\": 64,\n",
    "}\n",
    "\n",
    "run_3k_context = pf.run(flow=flow_path, data=data_path, column_mapping=column_mapping)\n",
    "pf.stream(run_3k_context)\n",
    "\n",
    "print(run_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-27 08:56:29 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run eval_groundedness_variant_0_20250227_085629_061524, log path: /home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085629_061524/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=eval_groundedness_variant_0_20250227_085629_061524\n",
      "2025-02-27 08:56:34 +0000   80186 execution.bulk     INFO     Process 80237 terminated.\n",
      "2025-02-27 08:56:34 +0000   80186 execution.bulk     WARNING  Process 80230 had been terminated.\n",
      "2025-02-27 08:56:34 +0000   80186 execution.bulk     WARNING  Process 80245 had been terminated.\n",
      "2025-02-27 08:56:30 +0000   73187 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-27 08:56:30 +0000   73187 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
      "2025-02-27 08:56:32 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-10:1)-Process id(80230)-Line number(0) start execution.\n",
      "2025-02-27 08:56:32 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-10:3)-Process id(80245)-Line number(1) start execution.\n",
      "2025-02-27 08:56:32 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-10:2)-Process id(80237)-Line number(2) start execution.\n",
      "2025-02-27 08:56:33 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-10:2)-Process id(80237)-Line number(2) completed.\n",
      "2025-02-27 08:56:33 +0000   73187 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-02-27 08:56:33 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 3.0 seconds. Estimated time for incomplete lines: 6.0 seconds.\n",
      "2025-02-27 08:56:33 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-10:3)-Process id(80245)-Line number(1) completed.\n",
      "2025-02-27 08:56:33 +0000   73187 execution.bulk     INFO     Process name(ForkProcess-10:1)-Process id(80230)-Line number(0) completed.\n",
      "2025-02-27 08:56:34 +0000   73187 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-02-27 08:56:34 +0000   73187 execution.bulk     INFO     Average execution time for completed lines: 1.33 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-27 08:56:34 +0000   73187 execution.bulk     INFO     The thread monitoring the process [80237-ForkProcess-10:2] will be terminated.\n",
      "2025-02-27 08:56:34 +0000   73187 execution.bulk     INFO     The thread monitoring the process [80230-ForkProcess-10:1] will be terminated.\n",
      "2025-02-27 08:56:34 +0000   73187 execution.bulk     INFO     The thread monitoring the process [80245-ForkProcess-10:3] will be terminated.\n",
      "2025-02-27 08:56:34 +0000   80237 execution.bulk     INFO     The process [80237] has received a terminate signal.\n",
      "2025-02-27 08:56:34 +0000   80230 execution.bulk     INFO     The process [80230] has received a terminate signal.\n",
      "2025-02-27 08:56:34 +0000   80245 execution.bulk     INFO     The process [80245] has received a terminate signal.\n",
      "2025-02-27 08:56:35 +0000   73187 execution.bulk     INFO     Executing aggregation node...\n",
      "2025-02-27 08:56:35 +0000   73187 execution.bulk     INFO     Finish executing aggregation node.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"eval_groundedness_variant_0_20250227_085629_061524\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-27 08:56:29.046979+00:00\"\n",
      "Duration: \"0:00:06.130410\"\n",
      "Output path: \"/home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085629_061524\"\n",
      "\n",
      "name: eval_groundedness_variant_0_20250227_085629_061524\n",
      "created_on: '2025-02-27T08:56:29.046979+00:00'\n",
      "status: Completed\n",
      "display_name: eval_groundedness_3k_context\n",
      "description:\n",
      "tags:\n",
      "properties:\n",
      "  flow_path: /home/azureuser/promptflow-demo/evaluation/eval-groundedness\n",
      "  output_path: \n",
      "    /home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085629_061524\n",
      "  column_mapping:\n",
      "    question: ${run.inputs.question}\n",
      "    answer: ${run.outputs.answer}\n",
      "    context: ${run.outputs.context}\n",
      "  system_metrics:\n",
      "    total_tokens: 0\n",
      "    prompt_tokens: 0\n",
      "    completion_tokens: 0\n",
      "    duration: 5.118315\n",
      "flow_name: eval-groundedness\n",
      "data:\n",
      "output: \n",
      "  /home/azureuser/.promptflow/.runs/eval_groundedness_variant_0_20250227_085629_061524/flow_outputs\n",
      "run: flow_variant_0_20250227_085610_947108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_groundedness_3k_context = pf.run(\n",
    "    flow=eval_groundedness_flow_path,\n",
    "    run=run_3k_context,\n",
    "    column_mapping={\n",
    "        \"question\": \"${run.inputs.question}\",\n",
    "        \"answer\": \"${run.outputs.answer}\",\n",
    "        \"context\": \"${run.outputs.context}\",\n",
    "    },\n",
    "    display_name=\"eval_groundedness_3k_context\",\n",
    ")\n",
    "pf.stream(eval_groundedness_3k_context)\n",
    "\n",
    "print(eval_groundedness_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the main difference between BERT and p...</td>\n",
       "      <td>BERT differs from earlier language representat...</td>\n",
       "      <td>['BERT: Pre-training of Deep Bidirectional Tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the size of the vocabulary used by BERT?</td>\n",
       "      <td>The provided contexts do not specify the exact...</td>\n",
       "      <td>['E (L=12, H=768, A=12, Total Param-\\neters=11...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>论文写作中论文引言有什么注意事项？</td>\n",
       "      <td>撰写学术论文时，引言部分应包括第一章引言（或绪论、序言、导论等），内容要有逻辑性，并且严格遵...</td>\n",
       "      <td>['须言之成理，论据可靠 ，严格遵循本学科国际通行的学术规范。 内容包括：第 一\\n章引言（...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     inputs.question  \\\n",
       "0  What is the main difference between BERT and p...   \n",
       "1   What is the size of the vocabulary used by BERT?   \n",
       "2                                  论文写作中论文引言有什么注意事项？   \n",
       "\n",
       "                                       inputs.answer  \\\n",
       "0  BERT differs from earlier language representat...   \n",
       "1  The provided contexts do not specify the exact...   \n",
       "2  撰写学术论文时，引言部分应包括第一章引言（或绪论、序言、导论等），内容要有逻辑性，并且严格遵...   \n",
       "\n",
       "                                      inputs.context  inputs.line_number  \\\n",
       "0  ['BERT: Pre-training of Deep Bidirectional Tra...                   0   \n",
       "1  ['E (L=12, H=768, A=12, Total Param-\\neters=11...                   1   \n",
       "2  ['须言之成理，论据可靠 ，严格遵循本学科国际通行的学术规范。 内容包括：第 一\\n章引言（...                   2   \n",
       "\n",
       "   outputs.groundedness  \n",
       "0                     9  \n",
       "1                     1  \n",
       "2                     7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_details(eval_groundedness_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groundedness': 5.666666666666667}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_metrics(eval_groundedness_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file is generated at '/tmp/pf-visualize-detail-g_y063kw.html'.\n",
      "Trying to view the result in a web browser...\n",
      "Successfully visualized from the web browser.\n"
     ]
    }
   ],
   "source": [
    "pf.visualize([eval_groundedness_2k_context, eval_groundedness_3k_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "build_doc": {
   "author": [
    "wangchao1230@github.com",
    "ttthree@github.com"
   ],
   "category": "local",
   "section": "Rag",
   "weight": 10
  },
  "description": "A tutorial of chat-with-pdf flow that allows user ask questions about the content of a PDF file and get answers",
  "kernelspec": {
   "display_name": "pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
